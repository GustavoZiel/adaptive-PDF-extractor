<div align="center">

<picture>
  <img alt="Adaptive Extractor Logo" src="docs/assets/logo.svg" width="25%" height="25%">
</picture>

**An PDF information extraction tool powered by LLM feedback optimization via caching.**

<h3>

[Documentation](docs/) â€¢ [Experiments](docs/experiment.md) â€¢ [Report](https://wandb.ai/gustavogrib-ggr-usp/adaptive-pdf-extractor/reports/Adaptative-PDF-Extractor-Analysis--VmlldzoxNDk4MjY0OQ?accessToken=sdl3m4ghmnv8tdnho85ia68qoxi88phpr9xp0pduj0lnjwfwwju1lg9fn38rr5tw)

[![License](https://img.shields.io/badge/License-MIT-blue.svg)](./LICENSE)
[![Python Version](https://img.shields.io/badge/Python-3.11+-blue.svg)](https://www.python.org/downloads/release/python-3110/)

</div>

<!-- # TODO - Melhorar, deixar mais direto e curto, apenas as porcentagens, redirecionar para o relatÃ³rio completo com todos os detalhes.

## ðŸ”¥ **Resultados Principais**

ðŸ’¡ **Desempenho de ReferÃªncia (1.000 documentos sintÃ©ticos):**  

- ðŸ§  **PrecisÃ£o mÃ©dia:** `91.38%`  
- âš¡ **Tempo mÃ©dio de processamento:** `3.28s`  
- ðŸ’° **ReduÃ§Ã£o progressiva de custo:** via **cache adaptativo de regras**

ðŸ“Š **Comparativo:**  

- Esta implementaÃ§Ã£o supera a extraÃ§Ã£o base (**LLM puro**) com:  
  - âž¡ï¸ **â€“X%** de tempo de processamento  
  - âž¡ï¸ **â€“Y%** de custo total  
  - sem comprometer a **alta precisÃ£o**. -->

## VisÃ£o Geral

Este projeto apresenta um **pipeline inteligente de extraÃ§Ã£o de dados** que aprende com o feedback de um LLM para reduzir progressivamente custos e tempo de processamento, mantendo uma alta precisÃ£o. Em vez de chamar LLMs caros para cada documento, resumidamente, o sistema:

1. **Extrai dados estruturados** de PDFs (com OCR) usando uma primeira LLM (*Extractor*) (gpt-5-mini).
2. **Gera regras de extraÃ§Ã£o reutilizÃ¡veis** usando uma segunda LLM (*Rule Generator*), em padrÃµes regex, a partir de extraÃ§Ãµes bem-sucedidas.
3. **Armazena e valida** essas regras geradas em um loop de feedback adaptativo, ajustando os prompts de geraÃ§Ã£o por um nÃºmero definido de iteraÃ§Ãµes.
4. **Melhora progressivamente** a eficiÃªncia ao reutilizar regras validadas em documentos similares.

### A Pipeline "de cima"

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Â PDF Texto  â”‚
â”‚   (OCR) Â  Â  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
Â  Â  Â  Â â”‚
Â  Â  Â  Â â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    Cache Hit?
â”‚ Â Tentar Regras Â  Â  Â â”‚â”€â”€â”€â”€â”€â”€â”€â”€Simâ”€â”€â”€â”€â–¶ âœ“ ExtraÃ§Ã£o RÃ¡pida
â”‚ Â em Cache Â  Â  Â  Â  Â  â”‚ Â  Â  Â  Â  Â  Â  (Sem chamada ao LLM Extractor)
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Â  Â  Â  Â â”‚ NÃ£o
Â  Â  Â  Â â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Â LLM Extractor Â  Â  Â â”‚ Â â—€â”€â”€ ExtraÃ§Ã£o estruturada
â”‚ Â (gpt-5-mini) Â  Â  Â  â”‚ Â  Â  Â  com schema Pydantic
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Â  Â  Â  Â â”‚
Â  Â  Â  Â â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LLM Rule Generator â”‚ Â â—€â”€â”€ Gera regras regex
â”‚ Â (gpt-5-mini)    Â   â”‚ Â  Â  Â   com validaÃ§Ã£o
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Â  Â  Â  Â â”‚
Â  Â  Â  Â â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Â Loop de Feedback Â  â”‚ Â â—€â”€â”€ Valida e refina as regras geradas
â”‚ Â (ValidaÃ§Ã£o) Â  Â  Â   â”‚ Â  Â  Â      (max N tentativas)
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Â  Â  Â  Â â”‚
Â  Â  Â  Â â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Â Cache Adaptativo Â  â”‚ Â â—€â”€â”€ Armazena regras
â”‚ Â (LRU + Pesos) Â  Â  Â â”‚ Â  Â  Â validadas para uso futuro
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**A OtimizaÃ§Ã£o**: Ao gerar e armazenar regras de extraÃ§Ã£o, cada extraÃ§Ã£o bem-sucedida torna o sistema mais rÃ¡pido e barato para os prÃ³ximos documentos **similares**. A cache se adapta usando um LRU (Least Recently Used) ponderado, priorizando regras frequentemente bem-sucedidas.

## Experimentos e Resultados

Acesse o **[RelatÃ³rio do Weights & Biases](https://wandb.ai/gustavogrib-ggr-usp/adaptive-pdf-extractor/reports/Adaptative-PDF-Extractor-Analysis--VmlldzoxNDk4MjY0OQ?accessToken=sdl3m4ghmnv8tdnho85ia68qoxi88phpr9xp0pduj0lnjwfwwju1lg9fn38rr5tw)** para a visualizaÃ§Ã£o completa dos experimentos.

Veja a **[DocumentaÃ§Ã£o de Experimentos](./docs/experiment.md)** para anÃ¡lise detalhada dos experimentos realizados.

## DocumentaÃ§Ã£o Extendida

### Conceitos Principais

* **[Arquitetura do Pipeline](./docs/pipeline.md)** â€” Pipeline de 3 etapas com fast/slow path e aprendizado de regras
* **[Sistema de Cache Adaptativo](./docs/cache.md)** â€” Cache LRU com priorizaÃ§Ã£o ponderada de regras
* **[GeraÃ§Ã£o e ValidaÃ§Ã£o de Regras](./docs/rule.md)** â€” Como as regras sÃ£o criadas, validadas e refinadas
* **[GeraÃ§Ã£o de Dados SintÃ©ticos](./docs/fake_data.md)** â€” Simulando documentos OCR com ruÃ­dos e variaÃ§Ãµes

## Como Rodar

```bash
# Clone esse repositÃ³rio e entre no seu diretÃ³rio
git clone https://github.com/GustavoZiel/adaptive-PDF-extractor.git
cd adaptive-PDF-extractor

# Instale as dependÃªncias
uv sync

# Ative o ambiente virtual
source .venv/bin/activate

# Crie um arquivo .env na raiz do projeto (Seguindo exemplo em .env.example)
cp .env.example .env

# Configure a API key do OpenAI no .env
echo 'OPENAI_API_KEY="sua_api_key_aqui"' >> .env

# Configure a API key do Weights & Biases no .env (opcional, para tracking de experimentos)
echo 'WANDB_API_KEY="sua_api_key_aqui"' >> .env

# Veja todas as opÃ§Ãµes de configuraÃ§Ã£o da pipeline
uv run src/main.py --help

# Veja todas as opÃ§Ãµes de configuraÃ§Ã£o para geraÃ§Ã£o de dados sintÃ©ticos
python3 -m scripts.generate_fake_data --help

# Gere dados sintÃ©ticos de exemplo (1.000 documentos)
python3 -m scripts.generate_fake_data \
  --save-path data/fake \
  --dataset-filename dataset \
  --num-samples 1000 \
  --seed 1

# Rode o pipeline nos dados de exemplo OU expecifique o caminho para seus prÃ³prios dados
uv run src/main.py \
  --data-folder data/fake \
  --dataset-filename dataset \
  --cache-filename cache \
  --max-attempts 5 \
  --use-wandb
```

## Estrutura do Projeto

```text
enter_ai_fellowship/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.py          # OrquestraÃ§Ã£o principal do pipeline
â”‚   â”œâ”€â”€ cache.py         # Sistema de cache LRU adaptativo
â”‚   â”œâ”€â”€ rule.py          # GeraÃ§Ã£o e execuÃ§Ã£o de regras
â”‚   â”œâ”€â”€ pipeline.py      # FunÃ§Ãµes de extraÃ§Ã£o (cache/LLM/rules)
â”‚   â”œâ”€â”€ llm.py           # InicializaÃ§Ã£o dos LLMs e prompts
â”‚   â”œâ”€â”€ data.py          # Processamento de dados e PDFs
â”‚   â”œâ”€â”€ metrics.py       # Tracking de mÃ©tricas e WandB
â”‚   â””â”€â”€ logger.py        # Sistema de logging
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ generate_fake_data.py  # GeraÃ§Ã£o de dados sintÃ©ticos
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ fake/            # Dados sintÃ©ticos gerados
â”‚   â””â”€â”€ real/            # Dados reais
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ pipeline.md      # Arquitetura do pipeline
â”‚   â”œâ”€â”€ cache.md         # Sistema de cache adaptativo
â”‚   â”œâ”€â”€ rule.md          # GeraÃ§Ã£o e validaÃ§Ã£o de regras
â”‚   â”œâ”€â”€ fake_data.md     # GeraÃ§Ã£o de dados sintÃ©ticos
â”‚   â”œâ”€â”€ experiment.md    # Experimentos realizados
â”‚   â”œâ”€â”€ architecture.md  # (em desenvolvimento)
â”‚   â””â”€â”€ assets/          # Imagens e diagramas
â”œâ”€â”€ ai-fellowship-data/  # Dataset original do desafio
â””â”€â”€ wandb/               # Logs do Weights & Biases
```

## Tecnologias Utilizadas

* **LLM**: OpenAI gpt-5-mini (configurÃ¡vel)
* **ValidaÃ§Ã£o**: Pydantic para saÃ­das estruturadas
* **Tracking**: Weights & Biases + Weave para log de experimentos
* **Linguagem**: Python 3.11+

## Agradecimentos

AgradeÃ§o a oportunidade de realizar esse projeto, me diverti bastante e aprendi muito tambÃ©m! ðŸš€

> Gustavo
