<div align="center">

<picture>
  <img alt="Adaptive Extractor Logo" src="docs/assets/logo.svg" width="25%" height="25%">
</picture>

**An PDF information extraction tool powered by LLM feedback optimization via caching.**

<h3>

[Documentation](docs/) â€¢ [Experiments](examples/) â€¢ [Report](reports/)

[![License](https://img.shields.io/badge/License-MIT-blue.svg)](./LICENSE)
[![Python Version](https://img.shields.io/badge/Python-3.11+-blue.svg)](https://www.python.org/downloads/release/python-3110/)

</div>

# TODO - Melhorar, deixar mais direto e curto, apenas as porcentagens, redirecionar para o relatÃ³rio completo com todos os detalhes.

## ðŸ”¥ **Resultados Principais**

ðŸ’¡ **Desempenho de ReferÃªncia (1.000 documentos sintÃ©ticos):**  

- ðŸ§  **PrecisÃ£o mÃ©dia:** `91.38%`  
- âš¡ **Tempo mÃ©dio de processamento:** `3.28s`  
- ðŸ’° **ReduÃ§Ã£o progressiva de custo:** via **cache adaptativo de regras**

ðŸ“Š **Comparativo:**  

- Esta implementaÃ§Ã£o supera a extraÃ§Ã£o base (**LLM puro**) com:  
  - âž¡ï¸ **â€“X%** de tempo de processamento  
  - âž¡ï¸ **â€“Y%** de custo total  
  - sem comprometer a **alta precisÃ£o**.

## VisÃ£o Geral

Este projeto apresenta um **pipeline inteligente de extraÃ§Ã£o de dados** que aprende com o feedback de um LLM para reduzir progressivamente custos e tempo de processamento, mantendo uma alta precisÃ£o. Em vez de chamar LLMs caros para cada documento, resumidamente, o sistema:

1. **Extrai dados estruturados** de PDFs (com OCR) usando uma primeira LLM (*Extractor*) (gpt-5-mini).
2. **Gera regras de extraÃ§Ã£o reutilizÃ¡veis** usando uma segunda LLM (*Rule Generator*), em padrÃµes regex, a partir de extraÃ§Ãµes bem-sucedidas.
3. **Armazena e valida** essas regras geradas em um loop de feedback adaptativo, ajustando os prompts de geraÃ§Ã£o por um nÃºmero definido de iteraÃ§Ãµes.
4. **Melhora progressivamente** a eficiÃªncia ao reutilizar regras validadas em documentos similares.

### A Pipeline "de cima"

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Â PDF Texto  â”‚
â”‚   (OCR) Â  Â  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
Â  Â  Â  Â â”‚
Â  Â  Â  Â â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    Cache Hit?
â”‚ Â Tentar Regras Â  Â  Â â”‚â”€â”€â”€â”€â”€â”€â”€â”€Simâ”€â”€â”€â”€â–¶ âœ“ ExtraÃ§Ã£o RÃ¡pida
â”‚ Â em Cache Â  Â  Â  Â  Â  â”‚ Â  Â  Â  Â  Â  Â  (Sem chamada ao LLM Extractor)
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Â  Â  Â  Â â”‚ NÃ£o
Â  Â  Â  Â â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Â LLM Extractor Â  Â  Â â”‚ Â â—€â”€â”€ ExtraÃ§Ã£o estruturada
â”‚ Â (gpt-5-mini) Â  Â  Â  â”‚ Â  Â  Â  com schema Pydantic
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Â  Â  Â  Â â”‚
Â  Â  Â  Â â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LLM Rule Generator â”‚ Â â—€â”€â”€ Gera regras regex
â”‚ Â (gpt-5-mini)    Â   â”‚ Â  Â  Â   com validaÃ§Ã£o
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Â  Â  Â  Â â”‚
Â  Â  Â  Â â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Â Loop de Feedback Â  â”‚ Â â—€â”€â”€ Valida e refina as regras geradas
â”‚ Â (ValidaÃ§Ã£o) Â  Â  Â   â”‚ Â  Â  Â      (max N tentativas)
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Â  Â  Â  Â â”‚
Â  Â  Â  Â â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Â Cache Adaptativo Â  â”‚ Â â—€â”€â”€ Armazena regras
â”‚ Â (LRU + Pesos) Â  Â  Â â”‚ Â  Â  Â validadas para uso futuro
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**A OtimizaÃ§Ã£o**: Ao gerar e armazenar regras de extraÃ§Ã£o, cada extraÃ§Ã£o bem-sucedida torna o sistema mais rÃ¡pido e barato para os prÃ³ximos documentos **similares**. A cache se adapta usando um LRU (Least Recently Used) ponderado, priorizando regras frequentemente bem-sucedidas.

## Experimentos e Resultados

Acesse o **[RelatÃ³rio do Weights & Biases](https://wandb.ai/your_username/your_project)** para a visualizaÃ§Ã£o completa dos experimentos.

Veja a [DocumentaÃ§Ã£o de Experimentos](https://www.google.com/search?q=./docs/experiments.md) para a anÃ¡lise detalhada.

## DocumentaÃ§Ã£o Extendida

### Conceitos Principais

- **[Arquitetura do Pipeline](https://www.google.com/search?q=./docs/pipeline.md)** - Como o sistema dual-LLM funciona
- **[Sistema de Cache Adaptativo](https://www.google.com/search?q=./docs/cache.md)** - Cache LRU com priorizaÃ§Ã£o ponderada de regras
- **[GeraÃ§Ã£o e ValidaÃ§Ã£o de Regras](https://www.google.com/search?q=./docs/rules.md)** - Como as regras sÃ£o criadas, validadas e refinadas
- **[GeraÃ§Ã£o de Dados SintÃ©ticos](https://www.google.com/search?q=./docs/synthetic_data.md)** - Simulando a imprecisÃ£o de documentos OCR

## Como Rodar

```bash
# Clone esse repositÃ³rio e entre no seu diretÃ³rio
git clone https://github.com/GustavoZiel/adaptive-PDF-extractor.git
cd adaptive-PDF-extractor

# Instale as dependÃªncias
uv sync

# Ative o ambiente virtual
source .venv/bin/activate

# Crie um arquivo .env na raiz do projeto (Seguindo exemplo em .env.example)
cp .env.example .env

# Configure a API key do OpenAI no .env
echo 'OPENAI_API_KEY="sua_api_key_aqui"' >> .env

# Veja todas as opÃ§Ãµes de configuraÃ§Ã£o da pipeline
uv run src/main.py --help

# Veja todas as opÃ§Ãµes de configuraÃ§Ã£o para geraÃ§Ã£o de dados sintÃ©ticos
python3 -m scripts.generate_fake_data --help

# Gere dados sintÃ©ticos de exemplo (1.000 documentos)
python3 -m scripts.generate_fake_data \
  --save-path data/fake \
  --dataset-filename dataset.json \
  --num-samples 1000 \
  --seed 1

# Rode o pipeline nos dados de exemplo
uv run src/main.py \
  --data-folder data/fake \
  --dataset-filename dataset.json \
  --cache-filename cache.json \
  --max-attempts 5 \
  --use-wandb
```

## Estrutura do Projeto

```text
enter_ai_fellowship/
â”œâ”€â”€ src/
â”‚ Â  â”œâ”€â”€ main.py Â  Â  Â  Â  Â  # OrquestraÃ§Ã£o principal do pipeline
â”‚ Â  â”œâ”€â”€ cache.py Â  Â  Â  Â  Â # ImplementaÃ§Ã£o do cache adaptativo
â”‚ Â  â”œâ”€â”€ rule.py Â  Â  Â  Â  Â  # GeraÃ§Ã£o e execuÃ§Ã£o de regras
â”‚ Â  â”œâ”€â”€ models.py Â  Â  Â  Â  # InicializaÃ§Ã£o dos LLMs e prompts
â”‚ Â  â””â”€â”€ utils.py Â  Â  Â  Â  Â # UtilitÃ¡rios de processamento de dados
â”œâ”€â”€ data/
â”‚ Â  â”œâ”€â”€ dataset.json Â  Â  Â # Documentos de entrada
â”‚ Â  â”œâ”€â”€ processed/ Â  Â  Â  Â # Resultados processados
â”‚ Â  â””â”€â”€ cache/ Â  Â  Â  Â  Â  Â # Regras de extraÃ§Ã£o em cache
â”œâ”€â”€ docs/ Â  Â  Â  Â  Â  Â  Â  Â  # DocumentaÃ§Ã£o detalhada
â”œâ”€â”€ notebooks/ Â  Â  Â  Â  Â  Â # Jupyter notebooks para anÃ¡lise
â””â”€â”€ Experiments/ Â  Â  Â  Â  Â # Resultados e mÃ©tricas de experimentos
```

## Tecnologias Utilizadas

- **LLM**: OpenAI gpt-5-mini (configurÃ¡vel)
- **Framework**: LangChain para orquestraÃ§Ã£o
- **ValidaÃ§Ã£o**: Pydantic para saÃ­das estruturadas
- **Tracking**: Weights & Biases + Weave para log de experimentos
- **Linguagem**: Python 3.11+

## Agradecimentos

AgradeÃ§o a oportunidade de realizar esse projeto, me diverti bastante e aprendi muito tambÃ©m! ðŸš€

> Gustavo
