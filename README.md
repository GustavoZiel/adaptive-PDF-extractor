<div align="center">

<picture>
  <img alt="Adaptive Extractor Logo" src="docs/assets/logo.svg" width="25%" height="25%">
</picture>

**An PDF information extraction tool powered by LLM feedback optimization via caching.**

<h3>

[Documentation](docs/) â€¢ [Experiments](docs/experiment.md) â€¢ [Report](https://wandb.ai/gustavogrib-ggr-usp/adaptive-pdf-extractor/reports/Adaptative-PDF-Extractor-Analysis--VmlldzoxNDk4MjY0OQ?accessToken=sdl3m4ghmnv8tdnho85ia68qoxi88phpr9xp0pduj0lnjwfwwju1lg9fn38rr5tw)

[![License](https://img.shields.io/badge/License-MIT-blue.svg)](./LICENSE)
[![Python Version](https://img.shields.io/badge/Python-3.11+-blue.svg)](https://www.python.org/downloads/release/python-3110/)

</div>

## ðŸ”¥ **Resultados Principais**

ðŸ’¡ **Desempenho de ReferÃªncia (1.000 documentos sintÃ©ticos):**

* **PrecisÃ£o mÃ©dia:** `â‰ˆ98%`
* **Tempo mÃ©dio de processamento:** `0.76s` *(com cache)*
* **Custo mÃ©dio:** **$0.12**
* **ReduÃ§Ã£o drÃ¡stica de chamadas Ã  LLM:** de **1000 â†’ 31**

ðŸ“Š **Comparativo direto:**

| CenÃ¡rio       | LLM Calls | Tempo MÃ©dio | Custo | Performance |
| ------------- | --------- | ----------- | ----- | ----------- |
| **Com Cache** | 31        | 0.76s       | $0.12 | 98.26%      |
| **Sem Cache** | 1000      | 13.61s      | $1.81 | 98.9%       |

ðŸš€ **Ganho obtido:**

* **â€“94%** no tempo de processamento
* **â€“93%** no custo total
* **PrecisÃ£o praticamente inalterada**

ðŸ”— **[Veja o experimento completo â†’](https://wandb.ai/gustavogrib-ggr-usp/adaptive-pdf-extractor/reports/Adaptative-PDF-Extractor-Analysis--VmlldzoxNDk4MjY0OQ?accessToken=sdl3m4ghmnv8tdnho85ia68qoxi88phpr9xp0pduj0lnjwfwwju1lg9fn38rr5tw)**

## VisÃ£o Geral

Este projeto apresenta um **pipeline inteligente de extraÃ§Ã£o de dados** que aprende com o feedback de um LLM para reduzir progressivamente custos e tempo de processamento, mantendo uma alta precisÃ£o. Em vez de chamar LLMs caros para cada documento, resumidamente, o sistema:

1. **Extrai dados estruturados** de PDFs (com OCR) usando uma primeira LLM (*Extractor*) (gpt-5-mini).
2. **Gera regras de extraÃ§Ã£o reutilizÃ¡veis** usando uma segunda LLM (*Rule Generator*), em padrÃµes regex, a partir de extraÃ§Ãµes bem-sucedidas.
3. **Armazena e valida** essas regras geradas em um loop de feedback adaptativo, ajustando os prompts de geraÃ§Ã£o por um nÃºmero definido de iteraÃ§Ãµes.
4. **Melhora progressivamente** a eficiÃªncia ao reutilizar regras validadas em documentos similares.

### A Pipeline "de cima"

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Â PDF Texto  â”‚
â”‚   (OCR) Â  Â  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
Â  Â  Â  Â â”‚
Â  Â  Â  Â â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    Cache Hit?
â”‚ Â Tentar Regras Â  Â  Â â”‚â”€â”€â”€â”€â”€â”€â”€â”€Simâ”€â”€â”€â”€â–¶ âœ“ ExtraÃ§Ã£o RÃ¡pida
â”‚ Â em Cache Â  Â  Â  Â  Â  â”‚ Â  Â  Â  Â  Â  Â  (Sem chamada ao LLM Extractor)
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Â  Â  Â  Â â”‚ NÃ£o
Â  Â  Â  Â â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Â LLM Extractor Â  Â  Â â”‚ Â â—€â”€â”€ ExtraÃ§Ã£o estruturada
â”‚ Â (gpt-5-mini) Â  Â  Â  â”‚ Â  Â  Â  com schema Pydantic
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Â  Â  Â  Â â”‚
Â  Â  Â  Â â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LLM Rule Generator â”‚ Â â—€â”€â”€ Gera regras regex
â”‚ Â (gpt-5-mini)    Â   â”‚ Â  Â  Â   com validaÃ§Ã£o
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Â  Â  Â  Â â”‚
Â  Â  Â  Â â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Â Loop de Feedback Â  â”‚ Â â—€â”€â”€ Valida e refina as regras geradas
â”‚ Â (ValidaÃ§Ã£o) Â  Â  Â   â”‚ Â  Â  Â      (max N tentativas)
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Â  Â  Â  Â â”‚
Â  Â  Â  Â â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Â Cache Adaptativo Â  â”‚ Â â—€â”€â”€ Armazena regras
â”‚ Â (LRU + Pesos) Â  Â  Â â”‚ Â  Â  Â validadas para uso futuro
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**A OtimizaÃ§Ã£o**: Ao gerar e armazenar regras de extraÃ§Ã£o, cada extraÃ§Ã£o bem-sucedida torna o sistema mais rÃ¡pido e barato para os prÃ³ximos documentos **similares**. A cache se adapta usando um LRU (Least Recently Used) ponderado, priorizando regras frequentemente bem-sucedidas.

## Experimentos e Resultados

Acesse o **[RelatÃ³rio do Weights & Biases](https://wandb.ai/gustavogrib-ggr-usp/adaptive-pdf-extractor/reports/Adaptative-PDF-Extractor-Analysis--VmlldzoxNDk4MjY0OQ?accessToken=sdl3m4ghmnv8tdnho85ia68qoxi88phpr9xp0pduj0lnjwfwwju1lg9fn38rr5tw)** para a visualizaÃ§Ã£o completa dos experimentos.

Veja a **[DocumentaÃ§Ã£o de Experimentos](./docs/experiment.md)** para anÃ¡lise detalhada dos experimentos realizados.

## DocumentaÃ§Ã£o Extendida

### Conceitos Principais

* **[Arquitetura do Pipeline](./docs/pipeline.md)** â€” Pipeline de 3 etapas com fast/slow path e aprendizado de regras
* **[Sistema de Cache Adaptativo](./docs/cache.md)** â€” Cache LRU com priorizaÃ§Ã£o ponderada de regras
* **[GeraÃ§Ã£o e ValidaÃ§Ã£o de Regras](./docs/rule.md)** â€” Como as regras sÃ£o criadas, validadas e refinadas
* **[GeraÃ§Ã£o de Dados SintÃ©ticos](./docs/fake_data.md)** â€” Simulando documentos OCR com ruÃ­dos e variaÃ§Ãµes

## Como Rodar

```bash
# Clone esse repositÃ³rio e entre no seu diretÃ³rio
git clone https://github.com/GustavoZiel/adaptive-PDF-extractor.git
cd adaptive-PDF-extractor

# Instale as dependÃªncias
uv sync

# Ative o ambiente virtual
source .venv/bin/activate

# Crie um arquivo .env na raiz do projeto (Seguindo exemplo em .env.example)
cp .env.example .env

# Configure a API key do OpenAI no .env
echo 'OPENAI_API_KEY="sua_api_key_aqui"' >> .env

# Configure a API key do Weights & Biases no .env (opcional, para tracking de experimentos)
echo 'WANDB_API_KEY="sua_api_key_aqui"' >> .env

# Veja todas as opÃ§Ãµes de configuraÃ§Ã£o da pipeline
uv run src/main.py --help

# Veja todas as opÃ§Ãµes de configuraÃ§Ã£o para geraÃ§Ã£o de dados sintÃ©ticos
python3 -m scripts.generate_fake_data --help

# Gere dados sintÃ©ticos de exemplo (1.000 documentos)
python3 -m scripts.generate_fake_data \
  --save-path data/fake \
  --dataset-filename dataset \
  --num-samples 1000 \
  --seed 1

# Rode o pipeline nos dados de exemplo OU expecifique o caminho para seus prÃ³prios dados
uv run src/main.py \
  --data-folder data/fake \
  --dataset-filename dataset \
  --cache-filename cache \
  --max-attempts 5 \
  --use-wandb
```

## Estrutura do Projeto

```text
enter_ai_fellowship/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.py          # OrquestraÃ§Ã£o principal do pipeline
â”‚   â”œâ”€â”€ cache.py         # Sistema de cache LRU adaptativo
â”‚   â”œâ”€â”€ rule.py          # GeraÃ§Ã£o e execuÃ§Ã£o de regras
â”‚   â”œâ”€â”€ pipeline.py      # FunÃ§Ãµes de extraÃ§Ã£o (cache/LLM/rules)
â”‚   â”œâ”€â”€ llm.py           # InicializaÃ§Ã£o dos LLMs e prompts
â”‚   â”œâ”€â”€ data.py          # Processamento de dados e PDFs
â”‚   â”œâ”€â”€ metrics.py       # Tracking de mÃ©tricas e WandB
â”‚   â””â”€â”€ logger.py        # Sistema de logging
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ generate_fake_data.py  # GeraÃ§Ã£o de dados sintÃ©ticos
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ fake/            # Dados sintÃ©ticos gerados
â”‚   â””â”€â”€ real/            # Dados reais
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ pipeline.md      # Arquitetura do pipeline
â”‚   â”œâ”€â”€ cache.md         # Sistema de cache adaptativo
â”‚   â”œâ”€â”€ rule.md          # GeraÃ§Ã£o e validaÃ§Ã£o de regras
â”‚   â”œâ”€â”€ fake_data.md     # GeraÃ§Ã£o de dados sintÃ©ticos
â”‚   â”œâ”€â”€ experiment.md    # Experimentos realizados
â”‚   â”œâ”€â”€ architecture.md  # (em desenvolvimento)
â”‚   â””â”€â”€ assets/          # Imagens e diagramas
â”œâ”€â”€ ai-fellowship-data/  # Dataset original do desafio
â””â”€â”€ wandb/               # Logs do Weights & Biases
```

## Tecnologias Utilizadas

* **LLM**: OpenAI gpt-5-mini (configurÃ¡vel)
* **ValidaÃ§Ã£o**: Pydantic para saÃ­das estruturadas
* **Tracking**: Weights & Biases + Weave para log de experimentos
* **Linguagem**: Python 3.11+

## LimitaÃ§Ãµes

* Como todo o sistema de otimizaÃ§Ã£o se baseia em expressÃµes regulares, o principal desafio Ã© criar regras que sejam suficientemente **gerais** para capturar variaÃ§Ãµes nos documentos, mas **especÃ­ficas** o bastante para evitar falsos positivos.
  * Documentos com formataÃ§Ãµes muito diferentes podem exigir muitas regras distintas e especÃ­ficas, o que pode limitar a eficiÃªncia da reutilizaÃ§Ã£o dos itens da cache.
  * A etapa de geraÃ§Ã£o das regras Ã© a mais custosa, portanto o nÃºmero mÃ¡ximo de tentativas deve ser balanceado para evitar custos excessivos.

* Lidar com valores nulos, seja em *labels* de campos ausentes ou em campos que podem ser opcionalmente vazios, tambÃ©m Ã© um desafio.
  * A estratÃ©gia adotada foi permitir que a LLM gere regras que retornem valores nulos quando apropriado, mas isso introduz uma complexidade adicional na construÃ§Ã£o e validaÃ§Ã£o das regras, resultando em um maior tempo de processamento.

* Para que a otimizaÃ§Ã£o completa ocorra, Ã© necessÃ¡rio preencher a cache com um nÃºmero suficiente de regras que generalizem o *noise* presente em um determinado lote (*batch*) de documentos. Quanto maior for a variabilidade entre os documentos, mais regras serÃ£o necessÃ¡rias para cobrir os casos, e, consequentemente, o tempo de processamento inicial serÃ¡ maior.
  * Imaginando um cenÃ¡rio em que todos os documentos sejam Ãºnicos entre sÃ­, o sistema nÃ£o conseguiria aproveitar a cache, resultando em um desempenho semelhante ao de uma extraÃ§Ã£o pura via LLM.

## Agradecimentos

AgradeÃ§o a oportunidade de realizar esse projeto, me diverti bastante e aprendi muito tambÃ©m! ðŸš€

> Gustavo
