{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "48945314",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "import os\n",
    "import re\n",
    "from pprint import pprint\n",
    "from typing import Any, Dict, List, Literal, Optional, Tuple\n",
    "from uuid import uuid4\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain.agents import create_agent\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from pydantic import BaseModel, Field, create_model\n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG, force=True)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "DATA_DIR = \"../data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e85b14cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_whitespace(text: str) -> str:\n",
    "    return \" \".join(text.split())\n",
    "\n",
    "\n",
    "def normalize_structure(text: str) -> str:\n",
    "    # 1. Add a space between conjoined letters and numbers\n",
    "    # (e.g., \"Seccional101943\" -> \"Seccional 101943\")\n",
    "    text = re.sub(r\"([a-zA-Z])(\\d)\", r\"\\1 \\2\", text)\n",
    "    text = re.sub(r\"(\\d)([a-zA-Z])\", r\"\\1 \\2\", text)\n",
    "\n",
    "    # 2. Add a space between conjoined words (e.g., \"GOKUInscrição\")\n",
    "    # This looks for a lowercase/uppercase letter, followed by an\n",
    "    # uppercase and then a lowercase (start of a new word).\n",
    "    text = re.sub(r\"([a-z])([A-Z])\", r\"\\1 \\2\", text)\n",
    "    text = re.sub(r\"([A-Z])([A-Z][a-z])\", r\"\\1 \\2\", text)\n",
    "\n",
    "    # 3. Collapse multiple spaces/tabs *on the same line* into one\n",
    "    text = re.sub(r\"[ \\t]+\", \" \", text)\n",
    "\n",
    "    # 4. Collapse multiple consecutive newlines into a single newline\n",
    "    # (e.g., \"\\n\\n\\n\" -> \"\\n\")\n",
    "    text = re.sub(r\"\\n+\", \"\\n\", text)\n",
    "\n",
    "    # 5. Remove any leading/trailing whitespace from the whole text\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "def clean_llm_output(text: str) -> str:\n",
    "    # if not text:\n",
    "    #     return text\n",
    "    # return normalize_whitespace(normalize_structure(text))\n",
    "    return text\n",
    "\n",
    "\n",
    "def read_dataset():\n",
    "    with open(os.path.join(DATA_DIR, \"dataset.json\"), \"r\", encoding=\"utf-8\") as f:\n",
    "        dataset = json.load(f)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def get_pdf_text(file_path):\n",
    "    reader = PdfReader(file_path)\n",
    "\n",
    "    assert len(reader.pages) > 0, \"PDF has no pages\"\n",
    "    assert len(reader.pages) == 1, \"PDF has more than one page\"\n",
    "\n",
    "    # return normalize_structure(reader.pages[0].extract_text())\n",
    "    return reader.pages[0].extract_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1204fb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # DEBUG NORMALIZATION\n",
    "# goku_text = \"K\"\n",
    "# clean_text = normalize_text(goku_text)\n",
    "# print(f\"'{clean_text}'\")\n",
    "# # Output: \"SON GOKU Inscrição Seccional 101943 PR Subseção\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0654257e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = read_dataset()\n",
    "for data in dataset:\n",
    "    pdf_path = os.path.join(DATA_DIR, data[\"pdf_path\"])\n",
    "    pdf_text = get_pdf_text(pdf_path)\n",
    "    data.update({\"pdf_text\": pdf_text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b1631efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JOANA D'ARC\n",
      "Inscrição Seccional Subseção\n",
      "101943 PR CONSELHO SECCIONAL - PARANÁ\n",
      "SUPLEMENTAR\n",
      "Endereço Profissional\n",
      "AVENIDA PAULISTA, Nº 2300 andar Pilotis, Bela Vista\n",
      "SÃO PAULO - SP\n",
      "01310300\n",
      "Telefone Profissional\n",
      "SITUAÇÃO REGULAR\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0][\"pdf_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3ef95eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pydantic_model(schema: Dict[str, Any]) -> BaseModel:\n",
    "    fields = {\n",
    "        key: (str | None, Field(default=None, description=value))\n",
    "        for key, value in schema.items()\n",
    "    }\n",
    "    model = create_model(\"DynamicModel\", **fields)\n",
    "    return model\n",
    "\n",
    "\n",
    "for data in dataset:\n",
    "    data.update({\"pydantic_model\": create_pydantic_model(data[\"extraction_schema\"])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "72676703",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = init_chat_model(\n",
    "    \"gemini-2.5-flash\",\n",
    "    model_provider=\"google_genai\",\n",
    "    api_key=os.getenv(\"GEMINI_API_KEY\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4831fcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_pt = \"\"\"\n",
    "Você receberá um trecho de texto extraído de um documento.\n",
    "\n",
    "Com base nesse texto, extraia **exclusivamente** as informações solicitadas e retorne o resultado em **formato JSON**, seguindo rigorosamente o esquema fornecido.\n",
    "\n",
    "Texto de entrada:\n",
    "{text}\n",
    "\n",
    "Esquema JSON esperado:\n",
    "{schema}\n",
    "\n",
    "Instruções importantes:\n",
    "- Se uma informação não estiver presente no texto, atribua o valor **null** ao campo correspondente.\n",
    "- Não adicione informações que não estejam explícitas no texto.\n",
    "- Retorne **apenas** o JSON, sem comentários, explicações ou texto adicional.\n",
    "- Garanta que o JSON seja **válido**, **bem formatado** e **compatível com o esquema**.\n",
    "\"\"\"\n",
    "\n",
    "prompt_template_en = \"\"\"\n",
    "You are a text extraction robot. Your task is to extract information from the `Input text` according to the `Extraction Schema`.\n",
    "\n",
    "Return **only** a valid JSON object.\n",
    "\n",
    "---\n",
    "**Input text:**\n",
    "{text}\n",
    "---\n",
    "**Extraction Schema:**\n",
    "{schema}\n",
    "---\n",
    "**Example of Correct Extraction:**\n",
    "\n",
    "* **Example Input Text Snippet:**\n",
    "    \"...\n",
    "    Telefone Profissional\n",
    "    SITUAÇÃO REGULAR\n",
    "    ...\"\n",
    "\n",
    "* **Example Schema:**\n",
    "    `{{\"situacao\": \"Situação do profissional\"}}`\n",
    "\n",
    "* **Correct Output (Verbatim):**\n",
    "    `{{\"situacao\": \"SITUAÇÃO REGULAR\"}}`\n",
    "\n",
    "* **Incorrect Output (Interpreted/Simplified):**\n",
    "    `{{\"situacao\": \"REGULAR\"}}`\n",
    "---\n",
    "**Important Instructions:**\n",
    "- **CRITICAL:** You must extract the text *verbatim* (exactly as it appears), as shown in the CORRECT example. Do not summarize, interpret, simplify, or rephrase.\n",
    "- If any information is missing from the text, assign the value **null** to the corresponding field.\n",
    "- Ensure your output contains **only** the JSON and nothing else (no comments, no explanations).\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "56f5aa6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_IDX = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "55b0bb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config = {\"configurable\": {\"thread_id\": str(uuid4())}}\n",
    "# memory = MemorySaver()\n",
    "agent = create_agent(\n",
    "    # model=model, tools=[], response_format=OABSchema, checkpointer=memory\n",
    "    model=model,\n",
    "    tools=[],\n",
    "    response_format=dataset[DATA_IDX][\"pydantic_model\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "637f9967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JOANA D'ARC\n",
      "Inscrição Seccional Subseção\n",
      "101943 PR CONSELHO SECCIONAL - PARANÁ\n",
      "SUPLEMENTAR\n",
      "Endereço Profissional\n",
      "AVENIDA PAULISTA, Nº 2300 andar Pilotis, Bela Vista\n",
      "SÃO PAULO - SP\n",
      "01310300\n",
      "Telefone Profissional\n",
      "SITUAÇÃO REGULAR\n"
     ]
    }
   ],
   "source": [
    "print(dataset[DATA_IDX][\"pdf_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "19e2e100",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = agent.invoke(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt_template_en.format(\n",
    "                    text=dataset[DATA_IDX][\"pdf_text\"],\n",
    "                    schema=dataset[DATA_IDX][\"pydantic_model\"],\n",
    "                ),\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    # config=config,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f6dff359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nome=\"JOANA D'ARC\" inscricao='101943' seccional='PR' subsecao='CONSELHO SECCIONAL - PARANÁ' categoria='SUPLEMENTAR' endereco_profissional='AVENIDA PAULISTA, Nº 2300 andar Pilotis, Bela Vista\\nSÃO PAULO - SP\\n01310300' telefone_profissional=None situacao='SITUAÇÃO REGULAR'\n"
     ]
    }
   ],
   "source": [
    "print(response[\"structured_response\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d9c893df",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = response[\"structured_response\"].model_dump()\n",
    "normalized_dict = {k: clean_llm_output(v) for k, v in model_dict.items()}\n",
    "response[\"structured_response\"] = dataset[DATA_IDX][\"pydantic_model\"](**normalized_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "d74f814c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nome=\"JOANA D'ARC\" inscricao='101943' seccional='PR' subsecao='CONSELHO SECCIONAL - PARANÁ' categoria='SUPLEMENTAR' endereco_profissional='AVENIDA PAULISTA, Nº 2300 andar Pilotis, Bela Vista\\nSÃO PAULO - SP\\n01310300' telefone_profissional=None situacao='SITUAÇÃO REGULAR'\n"
     ]
    }
   ],
   "source": [
    "print(response[\"structured_response\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e4516d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the exact types of rules that your system understands\n",
    "RuleType = Literal[\"regex\", \"keyword\", \"position\"]\n",
    "\n",
    "# Define the exact strategies for rules of type \"keyword\"\n",
    "KeywordStrategy = Literal[\"next_line\", \"multiline_until_stop\", \"conditional_null\"]\n",
    "\n",
    "\n",
    "class Rule(BaseModel):\n",
    "    \"\"\"Stores a single extraction rule generated by the Learning Loop.\"\"\"\n",
    "\n",
    "    # --- Main Discriminator Field ---\n",
    "    type: RuleType = Field(\n",
    "        ..., description=\"The main type of the rule (regex, keyword, or position)\"\n",
    "    )\n",
    "\n",
    "    # --- 1. For type=\"regex\" ---\n",
    "    rule: Optional[str] = Field(\n",
    "        None,\n",
    "        description=\"The regex pattern to be executed. (Ex: 'Inscrição[^\\d]*(\\d{6})')\",\n",
    "    )\n",
    "\n",
    "    # --- 2. For type=\"keyword\" ---\n",
    "    keyword: Optional[str] = Field(\n",
    "        None, description=\"The 'anchor' keyword to search for in the text.\"\n",
    "    )\n",
    "\n",
    "    strategy: Optional[KeywordStrategy] = Field(\n",
    "        None, description=\"The action to take after finding the keyword.\"\n",
    "    )\n",
    "\n",
    "    stop_keyword: Optional[str] = Field(\n",
    "        None,\n",
    "        description=\"Where to stop for 'multiline' or what to check for 'conditional'.\",\n",
    "    )\n",
    "\n",
    "    # --- 3. For type=\"position\" ---\n",
    "    line_number: Optional[int] = Field(\n",
    "        None,\n",
    "        description=\"The line number to extract (e.g., 1 for the first line).\",\n",
    "    )\n",
    "\n",
    "    # --- 4. Validation (Applies to all types) ---\n",
    "    validation_regex: str = Field(\n",
    "        ...,\n",
    "        description=\"A simple regex to validate the *format* of the extracted value (e.g., '^\\d{6}$').\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b15394d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rule_generation_prompt_template_en = \"\"\"\n",
    "You are an expert automation engineer specializing in robust text extraction.\n",
    "Your task is to generate **two** mandatory items:\n",
    "1.  A **single, robust extraction rule** for a specific data field.\n",
    "2.  A **mandatory `validation_regex`** to verify the format of the extracted data.\n",
    "\n",
    "The goal is to create an \"atomic\" rule that can find this value in future documents. The rule MUST be based on stable \"anchor\" keywords (like \"Inscrição\", \"Endereço Profissional\") or patterns directly related to **itself**, not based on the position of *other* fields.\n",
    "\n",
    "**Crucial Constraint: What to AVOID**\n",
    "* **DO NOT** create rules that depend on the relative position of *other* fields.\n",
    "* **Bad Rule (Coupled):** \"Find the text on the line after the 'inscricao' field.\"\n",
    "* **Good Rule (Atomic):** \"Find the text on the line after the keyword 'Subseção'.\"\n",
    "\n",
    "---\n",
    "**ANALYSIS PATHS:**\n",
    "\n",
    "**PATH A: If `field_value` is NOT null (e.g., \"JOANA D'ARC\")**\n",
    "1.  **Locate:** Find the `field_value` in the `full_text`.\n",
    "2.  **Find Anchor:** Analyze the text *immediately* surrounding the value to find a stable, unique keyword (like \"Nome\", \"Inscrição\", etc.).\n",
    "3.  **Generate Extraction Rule:** Create the best possible extraction rule (`type`, `rule`, etc.).\n",
    "4.  **Generate Validation Regex:** Analyze the `field_value` and create a `validation_regex` that matches its *format*. **This is a mandatory step.**\n",
    "\n",
    "**PATH B: If `field_value` IS null**\n",
    "1.  **Locate Anchor:** Find the \"anchor\" keyword for the field (e.g., \"Telefone Profissional\") in the `full_text`.\n",
    "2.  **Find Stop-Anchor:** Analyze the text *immediately following* this anchor. Find the *next* field's anchor (e.g., \"SITUAÇÃO REGULAR\").\n",
    "3.  **Generate Extraction Rule:** Create a `conditional_null` rule.\n",
    "4.  **Generate Validation Regex:** For a `null` value, the `validation_regex` **must be `null`**.\n",
    "\n",
    "---\n",
    "**INPUTS:**\n",
    "\n",
    "**1. Full Text (`full_text`):**\n",
    "{text}\n",
    "\n",
    "**2. Field to Analyze (`field_name`):**\n",
    "\"{field_name}\"\n",
    "\n",
    "**3. Extracted Value (`field_value`):** (This could be `null` or `None`)\n",
    "\"{field_value}\"\n",
    "\n",
    "**4. Field Description (`field_description`):**\n",
    "\"{field_description}\"\n",
    "\n",
    "---\n",
    "**OUTPUT INSTRUCTIONS:**\n",
    "\n",
    "Return **only** a single, valid JSON object for the generated rule, strictly adhering to the following `Rule` schema.\n",
    "**Both the extraction rule and the `validation_regex` are mandatory outputs** (unless `field_value` is `null`).\n",
    "\n",
    "**Rule Schema:**\n",
    "{{\n",
    "    \"type\": \"The type of rule. Use 'regex' whenever possible.\",\n",
    "    \"rule\": \"The Python-compatible regex pattern. It MUST include a capture group ( ).\",\n",
    "    \"keyword\": \"The 'anchor' keyword (use if 'regex' is not possible).\",\n",
    "    \"strategy\": \"The strategy for the 'keyword' (e.g., 'next_line', 'multiline_until_stop', 'conditional_null').\",\n",
    "    \"stop_keyword\": \"The stopping keyword for the strategy.\",\n",
    "    \"line_number\": \"The line number (use 'position' only as a last resort).\",\n",
    "    \"validation_regex\": \"MANDATORY. A regex to validate the *format* of the extracted value (e.g., '^\\d{{6}}$'). Must be `null` if and only if `field_value` is `null`.\"\n",
    "}}\n",
    "\n",
    "**Example for a `regex` rule (PATH A):**\n",
    "{{\n",
    "    \"type\": \"regex\",\n",
    "    \"rule\": \"Inscrição[^\\d]*(\\d{{6}})\",\n",
    "    \"keyword\": null,\n",
    "    \"strategy\": null,\n",
    "    \"stop_keyword\": null,\n",
    "    \"line_number\": null,\n",
    "    \"validation_regex\": \"^\\d{{6}}$\"\n",
    "}}\n",
    "\n",
    "**Example for a `keyword` rule (PATH A):**\n",
    "{{\n",
    "    \"type\": \"keyword\",\n",
    "    \"rule\": null,\n",
    "    \"keyword\": \"Subseção\",\n",
    "    \"strategy\": \"next_line\",\n",
    "    \"stop_keyword\": null,\n",
    "    \"line_number\": null,\n",
    "    \"validation_regex\": \"^[A-Z\\s-]+$\"\n",
    "}}\n",
    "\n",
    "**Example for a `conditional_null` rule (PATH B):**\n",
    "{{\n",
    "    \"type\": \"keyword\",\n",
    "    \"rule\": null,\n",
    "    \"keyword\": \"Telefone Profissional\",\n",
    "    \"strategy\": \"conditional_null\",\n",
    "    \"stop_keyword\": \"SITUAÇÃO\",\n",
    "    \"line_number\": null,\n",
    "    \"validation_regex\": null\n",
    "}}\n",
    "\n",
    "**Your Turn:**\n",
    "Generate the rule for the field `\"{field_name}\"`.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d2b8b8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config = {\"configurable\": {\"thread_id\": str(uuid4())}}\n",
    "# memory = MemorySaver()\n",
    "agent_rule = create_agent(\n",
    "    # model=model, tools=[], response_format=Rule, checkpointer=memory\n",
    "    model=model,\n",
    "    tools=[],\n",
    "    response_format=Rule,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f7010f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rule_generation_prompt(\n",
    "    text: str, field_name: str, field_value: str, field_description: str\n",
    ") -> str:\n",
    "    return rule_generation_prompt_template_en.format(\n",
    "        text=text,\n",
    "        field_name=field_name,\n",
    "        field_value=field_value,\n",
    "        field_description=field_description,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d431a336",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _execute_position_rule(rule: Rule, text: str) -> Optional[str]:\n",
    "    \"\"\"Applies a 'position' type rule.\"\"\"\n",
    "    if not rule.line_number or rule.line_number <= 0:\n",
    "        return None  # Invalid line number\n",
    "\n",
    "    lines = text.splitlines()\n",
    "\n",
    "    # -1 because line_number is 1-based, list is 0-based\n",
    "    line_index = rule.line_number - 1\n",
    "\n",
    "    if line_index < len(lines):\n",
    "        return lines[line_index].strip()\n",
    "\n",
    "    return None  # Line number out of range\n",
    "\n",
    "\n",
    "def _execute_keyword_rule(rule: Rule, text: str) -> Optional[str]:\n",
    "    \"\"\"Applies a 'keyword' type rule.\"\"\"\n",
    "    if not rule.keyword:\n",
    "        return None\n",
    "\n",
    "    # Find the keyword\n",
    "    keyword_pos = text.find(rule.keyword)\n",
    "    if keyword_pos == -1:\n",
    "        return None  # Keyword not found\n",
    "\n",
    "    # Get all text *after* the keyword\n",
    "    start_pos = keyword_pos + len(rule.keyword)\n",
    "    text_after = text[start_pos:]\n",
    "\n",
    "    # --- Apply Strategy ---\n",
    "\n",
    "    if rule.strategy == \"next_line\":\n",
    "        # Finds the first non-empty line after the keyword\n",
    "        for line in text_after.splitlines():\n",
    "            stripped_line = line.strip()\n",
    "            if stripped_line:\n",
    "                return stripped_line\n",
    "        return None  # No non-empty line found\n",
    "\n",
    "    elif rule.strategy == \"multiline_until_stop\":\n",
    "        if not rule.stop_keyword:\n",
    "            return text_after.strip()  # No stop, return all text after\n",
    "\n",
    "        # Find the stop_keyword *in the text after the keyword*\n",
    "        stop_pos = text_after.find(rule.stop_keyword)\n",
    "\n",
    "        if stop_pos != -1:\n",
    "            # Return everything between keyword and stop_keyword\n",
    "            return text_after[:stop_pos].strip()\n",
    "        else:\n",
    "            # Stop keyword wasn't found, so this rule fails\n",
    "            return None\n",
    "\n",
    "    elif rule.strategy == \"conditional_null\":\n",
    "        # This rule's job is to confirm a value is null.\n",
    "        # It succeeds *if* the text between keyword and stop_keyword is empty.\n",
    "        if not rule.stop_keyword:\n",
    "            return None  # This strategy requires a stop_keyword\n",
    "\n",
    "        # Check if the text immediately after the keyword (when stripped)\n",
    "        # starts with the stop_keyword.\n",
    "        if text_after.strip().startswith(rule.stop_keyword):\n",
    "            return None  # Success: The value is correctly identified as null.\n",
    "        else:\n",
    "            # Failure: There is text between the keywords.\n",
    "            # This rule's logic does not match.\n",
    "            return None\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "# (Assumes your Rule, RuleType, and KeywordStrategy models are defined)\n",
    "def _execute_regex_rule(rule: Rule, text: str) -> Optional[str]:\n",
    "    \"\"\"Applies a 'regex' type rule.\"\"\"\n",
    "    if not rule.rule:\n",
    "        return None\n",
    "\n",
    "    # re.DOTALL makes the '.' special character match any character,\n",
    "    # including a newline. This is crucial for multi-line fields.\n",
    "    match = re.search(rule.rule, text, re.DOTALL)\n",
    "\n",
    "    if match:\n",
    "        try:\n",
    "            # .group(1) extracts the text from the *first capture group*\n",
    "            # This is the standard for extraction regex.\n",
    "            return match.group(1).strip()\n",
    "        except IndexError:\n",
    "            # This happens if the regex matched but had NO capture group.\n",
    "            # We can fall back to group(0), the full match.\n",
    "            return match.group(0).strip()\n",
    "\n",
    "    return None  # No match found\n",
    "\n",
    "\n",
    "def execute_rule(rule: Rule, text: str) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Executes a given extraction rule on the input text.\n",
    "\n",
    "    This function acts as a dispatcher, calling the correct\n",
    "    sub-function based on the rule's 'type'.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if rule.type == \"regex\":\n",
    "            return _execute_regex_rule(rule, text)\n",
    "        elif rule.type == \"keyword\":\n",
    "            return _execute_keyword_rule(rule, text)\n",
    "        elif rule.type == \"position\":\n",
    "            return _execute_position_rule(rule, text)\n",
    "    except Exception as e:\n",
    "        # Catch any unexpected errors during rule execution\n",
    "        print(f\"Error executing rule (type: {rule.type}, rule: {rule.rule}): {e}\")\n",
    "        return None\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "29200b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEBUG CELL\n",
    "\n",
    "# pdf_text = dataset[DATA_IDX][\"pdf_text\"]\n",
    "# obj_schema = dataset[DATA_IDX][\"extraction_schema\"]\n",
    "# llm_response = response[\"structured_response\"].model_dump()\n",
    "\n",
    "# base_prompt = create_rule_generation_prompt(\n",
    "#     pdf_text, \"nome\", llm_response[\"nome\"], dataset[DATA_IDX][\"extraction_schema\"][\"nome\"]\n",
    "# )\n",
    "# response_rule = agent_rule.invoke(\n",
    "#     {\"messages\": [{\"role\": \"user\", \"content\": base_prompt}]}\n",
    "# )\n",
    "# execute_rule(response_rule[\"structured_response\"], pdf_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "8dbab4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _validate_syntax(\n",
    "    response: Dict[str, Any],\n",
    "    field_name: str,\n",
    "    attempt: int,\n",
    "    logger: logging.Logger,\n",
    ") -> Tuple[Optional[Rule], Optional[str]]:\n",
    "    stage = \"syntax_validation\"\n",
    "    try:\n",
    "        # 4. Validate Syntax (Schema)\n",
    "        rule = Rule.model_validate(response.get(\"structured_response\", {}))\n",
    "        extra = (\n",
    "            {\n",
    "                \"field\": field_name,\n",
    "                \"attempt\": attempt,\n",
    "                \"stage\": stage,\n",
    "            },\n",
    "        )\n",
    "        logger.debug(\n",
    "            f\"Syntax validation successful: {extra}\",\n",
    "        )\n",
    "        return rule, None\n",
    "    except Exception as e:\n",
    "        feedback = (\n",
    "            f\"- ATTEMPT {attempt} FAILED: The JSON was malformed or failed schema validation. \"\n",
    "            f\"Error: {e}. Make sure to return ONLY valid JSON matching the schema.\"\n",
    "        )\n",
    "        extra = (\n",
    "            {\n",
    "                \"field\": field_name,\n",
    "                \"attempt\": attempt,\n",
    "                \"stage\": stage,\n",
    "                \"error\": str(e),\n",
    "                \"raw_response\": response,\n",
    "            },\n",
    "        )\n",
    "        logger.warning(\n",
    "            f\"Syntax validation failed: {extra}\",\n",
    "        )\n",
    "        return None, feedback\n",
    "\n",
    "\n",
    "def _validate_extraction_rule(\n",
    "    rule: Rule,\n",
    "    text: str,\n",
    "    field_value: str,\n",
    "    field_name: str,\n",
    "    attempt: int,\n",
    "    logger: logging.Logger,\n",
    ") -> Optional[str]:\n",
    "    stage = \"extraction_validation\"\n",
    "    extracted_val = None\n",
    "    try:\n",
    "        # 5. Validate Rule Execution (the 'rule')\n",
    "        extracted_val = execute_rule(rule, text)  # Your re.search() function\n",
    "\n",
    "        if extracted_val == field_value:\n",
    "            extra = (\n",
    "                {\n",
    "                    \"field\": field_name,\n",
    "                    \"attempt\": attempt,\n",
    "                    \"stage\": stage,\n",
    "                    \"rule\": rule.rule,\n",
    "                    \"extracted\": extracted_val,\n",
    "                },\n",
    "            )\n",
    "            logger.debug(\n",
    "                f\"Extraction rule validation successful: {extra}\",\n",
    "            )\n",
    "            return None  # Success\n",
    "\n",
    "        # Mismatch failure\n",
    "        feedback = (\n",
    "            f\"- ATTEMPT {attempt} FAILED: The 'rule' was wrong. \"\n",
    "            f\"Rule: `{rule.rule}`\\n\"\n",
    "            f\"  - Extracted: `{extracted_val}`\\n\"\n",
    "            f\"  - Expected: `{field_value}`\\n\"\n",
    "            f\"Please create a more precise regex.\"\n",
    "        )\n",
    "        extra = (\n",
    "            {\n",
    "                \"field\": field_name,\n",
    "                \"attempt\": attempt,\n",
    "                \"stage\": stage,\n",
    "                \"rule\": rule.rule,\n",
    "                \"extracted\": extracted_val,\n",
    "                \"expected\": field_value,\n",
    "            },\n",
    "        )\n",
    "        logger.warning(\n",
    "            f\"Extraction rule mismatch: {extra}\",\n",
    "        )\n",
    "        return feedback\n",
    "\n",
    "    except Exception as e:\n",
    "        # Execution error\n",
    "        feedback = (\n",
    "            f\"- ATTEMPT {attempt} FAILED: Error executing 'rule' regex. \"\n",
    "            f\"Rule: `{rule.rule}`. Error: {e}\"\n",
    "        )\n",
    "        extra = (\n",
    "            {\n",
    "                \"field\": field_name,\n",
    "                \"attempt\": attempt,\n",
    "                \"stage\": stage,\n",
    "                \"rule\": rule.rule,\n",
    "                \"error\": str(e),\n",
    "            },\n",
    "        )\n",
    "        logger.warning(\n",
    "            f\"Extraction rule execution error: {extra}\",\n",
    "        )\n",
    "        return feedback\n",
    "\n",
    "\n",
    "def _validate_validation_regex(\n",
    "    rule: Rule,\n",
    "    field_value: str,\n",
    "    field_name: str,\n",
    "    attempt: int,\n",
    "    logger: logging.Logger,\n",
    ") -> Optional[str]:\n",
    "    stage = \"validation_regex_validation\"\n",
    "    try:\n",
    "        # 6. Validate Validation Execution (the 'validation_regex')\n",
    "        if re.match(rule.validation_regex, field_value):\n",
    "            extra = (\n",
    "                {\n",
    "                    \"field\": field_name,\n",
    "                    \"attempt\": attempt,\n",
    "                    \"stage\": stage,\n",
    "                    \"validation_regex\": rule.validation_regex,\n",
    "                    \"value_matched\": field_value,\n",
    "                },\n",
    "            )\n",
    "            logger.debug(\n",
    "                f\"Validation regex validation successful: {extra}\",\n",
    "            )\n",
    "            return None  # Success\n",
    "\n",
    "        # Mismatch failure\n",
    "        feedback = (\n",
    "            f\"- ATTEMPT {attempt} FAILED: The 'validation_regex' was wrong.\\n\"\n",
    "            f\"  - Regex: `{rule.validation_regex}`\\n\"\n",
    "            f\"  - Did not match the expected value: `{field_value}`\\n\"\n",
    "            f\"  - Please create a 'validation_regex' that fully matches the expected value.\"\n",
    "        )\n",
    "        extra = (\n",
    "            {\n",
    "                \"field\": field_name,\n",
    "                \"attempt\": attempt,\n",
    "                \"stage\": stage,\n",
    "                \"validation_regex\": rule.validation_regex,\n",
    "                \"expected_to_match\": field_value,\n",
    "            },\n",
    "        )\n",
    "        logger.warning(\n",
    "            f\"Validation regex mismatch: {extra}\",\n",
    "        )\n",
    "        return feedback\n",
    "\n",
    "    except Exception as e:\n",
    "        # Execution error\n",
    "        feedback = (\n",
    "            f\"- ATTEMPT {attempt} FAILED: Error in 'validation_regex'. \"\n",
    "            f\"Regex: `{rule.validation_regex}`. Error: {e}\"\n",
    "        )\n",
    "        extra = (\n",
    "            {\n",
    "                \"field\": field_name,\n",
    "                \"attempt\": attempt,\n",
    "                \"stage\": stage,\n",
    "                \"validation_regex\": rule.validation_regex,\n",
    "                \"error\": str(e),\n",
    "            },\n",
    "        )\n",
    "        logger.warning(\n",
    "            f\"Validation regex execution error: {extra}\",\n",
    "        )\n",
    "        return feedback\n",
    "\n",
    "\n",
    "def generate_robust_rule(\n",
    "    text: str,\n",
    "    field_name: str,\n",
    "    field_value: str,\n",
    "    field_description: str,\n",
    "    max_attempts: int = 3,\n",
    ") -> Optional[Rule]:\n",
    "    extra = (\n",
    "        {\n",
    "            \"field\": field_name,\n",
    "            \"field_value\": field_value,\n",
    "        },\n",
    "    )\n",
    "    logger.info(\n",
    "        f\"Starting robust rule generation for field '{field_name}' with value '{field_value}': {extra}\"\n",
    "    )\n",
    "\n",
    "    # 1. Prepare the base prompt\n",
    "    base_prompt = create_rule_generation_prompt(\n",
    "        text, field_name, field_value, field_description\n",
    "    )\n",
    "    feedback_history: List[str] = []  # Stores feedback from failures\n",
    "\n",
    "    for attempt in range(max_attempts):\n",
    "        current_attempt = attempt + 1\n",
    "        extra = (\n",
    "            {\n",
    "                \"field\": field_name,\n",
    "                \"current_attempt\": current_attempt,\n",
    "                \"max_attempts\": max_attempts,\n",
    "            },\n",
    "        )\n",
    "        logger.info(\n",
    "            f\"Starting attempt {current_attempt}/{max_attempts} for field '{field_name}': {extra}\"\n",
    "        )\n",
    "\n",
    "        # 2. Build the prompt with feedback (if any)\n",
    "        current_prompt = base_prompt\n",
    "        if feedback_history:\n",
    "            feedback_str = \"\\n\".join(feedback_history)\n",
    "            current_prompt += f\"\"\"\n",
    "            ---\n",
    "            You have tried before. Analyze the feedback and generate a new rule.\n",
    "\n",
    "            FEEDBACK FROM PREVIOUS ATTEMPTS:\n",
    "            {feedback_str}\n",
    "\n",
    "            Generate a new and CORRECTED rule JSON:\n",
    "            \"\"\"\n",
    "            extra = (\n",
    "                {\n",
    "                    \"current_attempt\": current_attempt,\n",
    "                    \"feedback_count\": len(feedback_history),\n",
    "                },\n",
    "            )\n",
    "            logger.debug(\n",
    "                f\"Feedback added to prompt for attempt {current_attempt}: {extra}\"\n",
    "            )\n",
    "\n",
    "        # 3. Invoke Agent (LLM)\n",
    "        extra = (\n",
    "            {\n",
    "                \"current_attempt\": current_attempt,\n",
    "            },\n",
    "        )\n",
    "        logger.info(f\"Invoking agent for attempt {current_attempt}: {extra}\")\n",
    "        response = agent_rule.invoke(\n",
    "            {\"messages\": [{\"role\": \"user\", \"content\": current_prompt}]}\n",
    "        )\n",
    "\n",
    "        # 4. Validate Syntax\n",
    "        rule, feedback = _validate_syntax(response, field_name, current_attempt, logger)\n",
    "        if feedback:\n",
    "            feedback_history.append(feedback)\n",
    "            continue  # Try again\n",
    "\n",
    "        # 5. Validate Rule Execution\n",
    "        feedback = _validate_extraction_rule(\n",
    "            rule, text, field_value, field_name, current_attempt, logger\n",
    "        )\n",
    "        if feedback:\n",
    "            feedback_history.append(feedback)\n",
    "            continue  # Try again\n",
    "\n",
    "        # 6. Validate Validation Regex\n",
    "        feedback = _validate_validation_regex(\n",
    "            rule, field_value, field_name, current_attempt, logger\n",
    "        )\n",
    "        if feedback:\n",
    "            feedback_history.append(feedback)\n",
    "            continue  # Try again\n",
    "\n",
    "        # 7. Success!\n",
    "        # All three validations (Syntax, Rule, Validation) passed.\n",
    "        extra = (\n",
    "            {\n",
    "                \"field\": field_name,\n",
    "                \"final_attempt\": current_attempt,\n",
    "                \"final_feedback_history\": \"\\n\".join(feedback_history),\n",
    "            },\n",
    "        )\n",
    "        logger.info(\n",
    "            f\"Rule generation successful for field '{field_name}' after {current_attempt} attempts: {extra}\",\n",
    "        )\n",
    "        return rule\n",
    "\n",
    "    # 8. Failure (after max_attempts)\n",
    "    extra = (\n",
    "        {\n",
    "            \"field\": field_name,\n",
    "            \"attempts\": max_attempts,\n",
    "            \"final_feedback_history\": \"\\n\".join(feedback_history),\n",
    "        },\n",
    "    )\n",
    "    logger.error(\n",
    "        f\"Failed to generate a valid rule for field '{field_name}' after {max_attempts} attempts: {extra}\",\n",
    "    )\n",
    "    print(f\"ALERT: Failed to generate a valid rule for field '{field_name}'.\")\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "3c525855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generate_robust_rule(\n",
    "#     text, field_name, field_value, field_description, max_attempts=3\n",
    "# ) -> Optional[Rule]:\n",
    "#     logger.debug(\n",
    "#         f\"Starting rule generation for field '{field_name}' with value '{field_value}'\"\n",
    "#     )\n",
    "\n",
    "#     # 1. Prepare the prompt\n",
    "#     #    (This is the prompt that requests the complete JSON,\n",
    "#     #     including 'rule' AND 'validation_regex')\n",
    "#     base_prompt = create_rule_generation_prompt(\n",
    "#         text, field_name, field_value, field_description\n",
    "#     )\n",
    "#     logger.debug(f\"Base prompt prepared for field '{field_name}'\")\n",
    "\n",
    "#     feedback_history = []  # Stores feedback from failures\n",
    "\n",
    "#     for attempt in range(max_attempts):\n",
    "#         logger.debug(f\"Attempt {attempt + 1} for field '{field_name}'\")\n",
    "\n",
    "#         # 2. Build the prompt with feedback (if any)\n",
    "#         current_prompt = base_prompt\n",
    "#         if feedback_history:\n",
    "#             feedback_str = \"\\n\".join(feedback_history)\n",
    "#             current_prompt += f\"\"\"\n",
    "#             ---\n",
    "#             You have tried before. Analyze the feedback and generate a new rule.\n",
    "\n",
    "#             FEEDBACK FROM PREVIOUS ATTEMPTS:\n",
    "#             {feedback_str}\n",
    "\n",
    "#             Generate a new and CORRECTED rule JSON:\n",
    "#             \"\"\"\n",
    "#             logger.debug(f\"Feedback added to prompt for attempt {attempt + 1}\")\n",
    "\n",
    "#         # 3. Invoke Agent (LLM2)\n",
    "#         logger.debug(f\"Invoking agent for attempt {attempt + 1}\")\n",
    "#         response = agent_rule.invoke(\n",
    "#             {\"messages\": [{\"role\": \"user\", \"content\": current_prompt}]}\n",
    "#         )\n",
    "\n",
    "#         # 4. Validate Syntax (Schema)\n",
    "#         try:\n",
    "#             rule = Rule.model_validate(response[\"structured_response\"])\n",
    "#             logger.debug(f\"Rule validation successful for attempt {attempt + 1}\")\n",
    "#         except Exception as e:\n",
    "#             feedback_history.append(\n",
    "#                 f\"- ATTEMPT {attempt + 1} FAILED: The JSON was malformed. \"\n",
    "#                 f\"Error: {e}. Make sure to return ONLY JSON.\"\n",
    "#             )\n",
    "#             logger.warning(f\"Rule validation failed for attempt {attempt + 1}: {e}\")\n",
    "#             continue  # Try again\n",
    "\n",
    "#         # 5. Validate Rule Execution (the 'rule')\n",
    "#         try:\n",
    "#             extracted_val = execute_rule(rule, text)  # Your re.search() function\n",
    "#             logger.debug(\n",
    "#                 f\"Extracted value for attempt {attempt + 1}: '{extracted_val}'\"\n",
    "#             )\n",
    "#         except Exception as e:\n",
    "#             feedback_history.append(\n",
    "#                 f\"- ATTEMPT {attempt + 1} FAILED: Error executing rule. Error: {e}\"\n",
    "#             )\n",
    "#             logger.warning(f\"Rule execution error for attempt {attempt + 1}: {e}\")\n",
    "#             continue  # Try again\n",
    "\n",
    "#         if extracted_val != field_value:\n",
    "#             feedback_history.append(\n",
    "#                 f\"- ATTEMPT {attempt + 1} FAILED: The 'rule' was wrong. \"\n",
    "#                 f\"Rule: `{rule.rule}`\\n\"\n",
    "#                 f\"   - Extracted: `{extracted_val}`\\n\"\n",
    "#                 f\"   - Expected: `{field_value}`\\n\"\n",
    "#                 f\"Please create a more precise regex.\"\n",
    "#             )\n",
    "#             logger.warning(\n",
    "#                 f\"Rule execution failed for attempt {attempt + 1}: extracted '{extracted_val}' != expected '{field_value}'\"\n",
    "#             )\n",
    "#             continue  # Try again\n",
    "\n",
    "#         # 6. Validate Validation Execution (the 'validation_regex')\n",
    "#         try:\n",
    "#             if not re.match(rule.validation_regex, field_value):\n",
    "#                 feedback_history.append(\n",
    "#                     f\"- ATTEMPT {attempt + 1} FAILED: The 'validation_regex' was wrong.\"\n",
    "#                     f\"Regex: `{rule.validation_regex}`\\n\"\n",
    "#                     f\"   - Did not match the expected value: `{field_value}`\\n\"\n",
    "#                     f\"Please create a 'validation_regex' that matches.\"\n",
    "#                 )\n",
    "#                 logger.warning(\n",
    "#                     f\"Validation regex failed for attempt {attempt + 1}: regex '{rule.validation_regex}' did not match '{field_value}'\"\n",
    "#                 )\n",
    "#                 continue  # Try again\n",
    "#         except Exception as e:\n",
    "#             feedback_history.append(\n",
    "#                 f\"- ATTEMPT {attempt + 1} FAILED: Error in validation regex. Error: {e}\"\n",
    "#             )\n",
    "#             logger.warning(f\"Validation regex error for attempt {attempt + 1}: {e}\")\n",
    "#             continue  # Try again\n",
    "\n",
    "#         # 7. Success!\n",
    "#         # All three validations (Syntax, Rule, Validation) passed.\n",
    "#         logger.debug(\n",
    "#             f\"Rule generation successful for field '{field_name}' after {attempt + 1} attempts\"\n",
    "#         )\n",
    "#         return rule\n",
    "\n",
    "#     # 8. Failure (after max_attempts)\n",
    "#     logger.error(\n",
    "#         f\"Failed to generate a valid rule for field '{field_name}' after {max_attempts} attempts\"\n",
    "#     )\n",
    "#     print(f\"ALERT: Failed to generate a valid rule for field '{field_name}'.\")\n",
    "#     return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "5a91265d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Starting robust rule generation for field 'nome' with value 'JOANA D'ARC': ({'field': 'nome', 'field_value': \"JOANA D'ARC\"},)\n",
      "INFO:__main__:Starting attempt 1/5 for field 'nome': ({'field': 'nome', 'current_attempt': 1, 'max_attempts': 5},)\n",
      "INFO:__main__:Invoking agent for attempt 1: ({'current_attempt': 1},)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating rule for field: nome with value: JOANA D'ARC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:__main__:Syntax validation successful: ({'field': 'nome', 'attempt': 1, 'stage': 'syntax_validation'},)\n",
      "WARNING:__main__:Extraction rule mismatch: ({'field': 'nome', 'attempt': 1, 'stage': 'extraction_validation', 'rule': \"^([A-Z\\\\s']+)\", 'extracted': \"JOANA D'ARC\\nI\", 'expected': \"JOANA D'ARC\"},)\n",
      "INFO:__main__:Starting attempt 2/5 for field 'nome': ({'field': 'nome', 'current_attempt': 2, 'max_attempts': 5},)\n",
      "DEBUG:__main__:Feedback added to prompt for attempt 2: ({'current_attempt': 2, 'feedback_count': 1},)\n",
      "INFO:__main__:Invoking agent for attempt 2: ({'current_attempt': 2},)\n",
      "DEBUG:__main__:Syntax validation successful: ({'field': 'nome', 'attempt': 2, 'stage': 'syntax_validation'},)\n",
      "DEBUG:__main__:Extraction rule validation successful: ({'field': 'nome', 'attempt': 2, 'stage': 'extraction_validation', 'rule': \"^([A-Z ']+)\", 'extracted': \"JOANA D'ARC\"},)\n",
      "DEBUG:__main__:Validation regex validation successful: ({'field': 'nome', 'attempt': 2, 'stage': 'validation_regex_validation', 'validation_regex': \"^[A-Z ']+$\", 'value_matched': \"JOANA D'ARC\"},)\n",
      "INFO:__main__:Rule generation successful for field 'nome' after 2 attempts: ({'field': 'nome', 'final_attempt': 2, 'final_feedback_history': \"- ATTEMPT 1 FAILED: The 'rule' was wrong. Rule: `^([A-Z\\\\s']+)`\\n  - Extracted: `JOANA D'ARC\\nI`\\n  - Expected: `JOANA D'ARC`\\nPlease create a more precise regex.\"},)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated rule for field nome : type='regex' rule=\"^([A-Z ']+)\" keyword=None strategy=None stop_keyword=None line_number=None validation_regex=\"^[A-Z ']+$\"\n"
     ]
    }
   ],
   "source": [
    "pdf_text = dataset[DATA_IDX][\"pdf_text\"]\n",
    "obj_schema = dataset[DATA_IDX][\"extraction_schema\"]\n",
    "llm_response = response[\"structured_response\"].model_dump()\n",
    "\n",
    "generated_rules = {}\n",
    "\n",
    "for field, value in llm_response.items():\n",
    "    print(\"Generating rule for field:\", field, \"with value:\", value)\n",
    "    if value is not None:\n",
    "        # Preparar os inputs para o NOVO prompt\n",
    "        field_name = field\n",
    "        field_value = value\n",
    "        field_description = dataset[DATA_IDX][\"extraction_schema\"][field]\n",
    "\n",
    "        # Criar o prompt de geração de regra\n",
    "        rule_prompt = rule_generation_prompt_template_en.format(\n",
    "            text=pdf_text,\n",
    "            field_name=field_name,\n",
    "            field_value=field_value,\n",
    "            field_description=field_description,\n",
    "        )\n",
    "\n",
    "        rule_object = generate_robust_rule(\n",
    "            pdf_text, field_name, field_value, field_description, max_attempts=5\n",
    "        )\n",
    "\n",
    "        generated_rules[field] = rule_object\n",
    "        print(\"Generated rule for field\", field, \":\", generated_rules[field])\n",
    "    break\n",
    "\n",
    "# # Agora você tem um \"Heuristic Store\" de altíssima qualidade\n",
    "# save_rules_to_store(\"carteira_oab\", generated_rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a54e4342",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nome': Rule(type='regex', rule=\"^([A-Z ']+)\", keyword=None, strategy=None, stop_keyword=None, line_number=None, validation_regex=\"^[A-Z ']+$\")}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "f0d1953b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'nome': \"JOANA D'ARC\"}\n"
     ]
    }
   ],
   "source": [
    "def apply_rules_to_text(rules: Dict[str, Any], text: str) -> Dict[str, str | None]:\n",
    "    results = {}\n",
    "\n",
    "    for field_name, rule in rules.items():\n",
    "        value = None\n",
    "        if rule is not None:\n",
    "            value = execute_rule(rule, text)\n",
    "        value = clean_llm_output(value) if value is not None else None\n",
    "        results[field_name] = value\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "extracted_values = apply_rules_to_text(generated_rules, pdf_text)\n",
    "pprint(extracted_values)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "enter-ai-fellowship",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
